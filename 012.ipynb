{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xavier and He Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Constant',\n",
       " 'GlorotNormal',\n",
       " 'GlorotUniform',\n",
       " 'Identity',\n",
       " 'Initializer',\n",
       " 'Ones',\n",
       " 'Orthogonal',\n",
       " 'RandomNormal',\n",
       " 'RandomUniform',\n",
       " 'TruncatedNormal',\n",
       " 'VarianceScaling',\n",
       " 'Zeros',\n",
       " 'constant',\n",
       " 'deserialize',\n",
       " 'get',\n",
       " 'glorot_normal',\n",
       " 'glorot_uniform',\n",
       " 'he_normal',\n",
       " 'he_uniform',\n",
       " 'identity',\n",
       " 'lecun_normal',\n",
       " 'lecun_uniform',\n",
       " 'ones',\n",
       " 'orthogonal',\n",
       " 'serialize',\n",
       " 'zeros']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in dir(keras.initializers) if not name.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x247fe908908>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x247fe908e48>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg',\n",
    "                                          distribution='uniform')\n",
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonsaturating Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deserialize',\n",
       " 'elu',\n",
       " 'exponential',\n",
       " 'get',\n",
       " 'hard_sigmoid',\n",
       " 'linear',\n",
       " 'relu',\n",
       " 'selu',\n",
       " 'serialize',\n",
       " 'sigmoid',\n",
       " 'softmax',\n",
       " 'softplus',\n",
       " 'softsign',\n",
       " 'tanh']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 6s 100us/sample - loss: 1.2810 - accuracy: 0.6205 - val_loss: 0.8869 - val_accuracy: 0.7160\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.7952 - accuracy: 0.7369 - val_loss: 0.7132 - val_accuracy: 0.7626\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.6817 - accuracy: 0.7726 - val_loss: 0.6385 - val_accuracy: 0.7896\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.6219 - accuracy: 0.7941 - val_loss: 0.5931 - val_accuracy: 0.8016\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.5829 - accuracy: 0.8074 - val_loss: 0.5607 - val_accuracy: 0.8164\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.5552 - accuracy: 0.8173 - val_loss: 0.5354 - val_accuracy: 0.8242\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.5338 - accuracy: 0.8225 - val_loss: 0.5166 - val_accuracy: 0.8300\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.5172 - accuracy: 0.8261 - val_loss: 0.5043 - val_accuracy: 0.8356\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.5039 - accuracy: 0.8306 - val_loss: 0.4889 - val_accuracy: 0.8384\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.4923 - accuracy: 0.8333 - val_loss: 0.4816 - val_accuracy: 0.8398\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 4s 65us/sample - loss: 1.3452 - accuracy: 0.6203 - val_loss: 0.9241 - val_accuracy: 0.7170\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.8196 - accuracy: 0.7364 - val_loss: 0.7314 - val_accuracy: 0.7602\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 3s 57us/sample - loss: 0.6970 - accuracy: 0.7702 - val_loss: 0.6517 - val_accuracy: 0.7876\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.6333 - accuracy: 0.7914 - val_loss: 0.6033 - val_accuracy: 0.8058\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 3s 57us/sample - loss: 0.5917 - accuracy: 0.8049 - val_loss: 0.5689 - val_accuracy: 0.8164\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.5619 - accuracy: 0.8144 - val_loss: 0.5417 - val_accuracy: 0.8222\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 3s 57us/sample - loss: 0.5392 - accuracy: 0.8206 - val_loss: 0.5214 - val_accuracy: 0.8300\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 3s 57us/sample - loss: 0.5215 - accuracy: 0.8256 - val_loss: 0.5075 - val_accuracy: 0.8352\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.5071 - accuracy: 0.8286 - val_loss: 0.4917 - val_accuracy: 0.8384\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.4946 - accuracy: 0.8320 - val_loss: 0.4839 - val_accuracy: 0.8376\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure elu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"elu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x2478c142948>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"elu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"selu\",\n",
    "                             kernel_initializer=\"lecun_normal\"))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"selu\",\n",
    "                                 kernel_initializer=\"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 20s 360us/sample - loss: 1.1558 - accuracy: 0.5592 - val_loss: 0.8964 - val_accuracy: 0.6488\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 17s 317us/sample - loss: 0.8153 - accuracy: 0.6876 - val_loss: 0.7265 - val_accuracy: 0.7274\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 17s 316us/sample - loss: 0.7815 - accuracy: 0.7148 - val_loss: 0.7316 - val_accuracy: 0.7278\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 17s 316us/sample - loss: 0.7364 - accuracy: 0.7339 - val_loss: 0.6408 - val_accuracy: 0.7650\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 17s 317us/sample - loss: 0.6470 - accuracy: 0.7632 - val_loss: 0.5619 - val_accuracy: 0.7880\n"
     ]
    }
   ],
   "source": [
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in bn1.variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'cond/Identity' type=Identity>,\n",
       " <tf.Operation 'cond_1/Identity' type=Identity>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1.updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 5s 93us/sample - loss: 0.8761 - accuracy: 0.7122 - val_loss: 0.5509 - val_accuracy: 0.8230\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 5s 92us/sample - loss: 0.5737 - accuracy: 0.8037 - val_loss: 0.4722 - val_accuracy: 0.8456\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 5s 83us/sample - loss: 0.5142 - accuracy: 0.8229 - val_loss: 0.4376 - val_accuracy: 0.8576\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 5s 82us/sample - loss: 0.4826 - accuracy: 0.8327 - val_loss: 0.4134 - val_accuracy: 0.8644\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.4570 - accuracy: 0.8413 - val_loss: 0.3989 - val_accuracy: 0.8650\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 5s 82us/sample - loss: 0.4432 - accuracy: 0.8454 - val_loss: 0.3870 - val_accuracy: 0.8696\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.4255 - accuracy: 0.8513 - val_loss: 0.3783 - val_accuracy: 0.8702\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.4149 - accuracy: 0.8532 - val_loss: 0.3709 - val_accuracy: 0.8746\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 4s 82us/sample - loss: 0.4015 - accuracy: 0.8599 - val_loss: 0.3637 - val_accuracy: 0.8754\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 5s 83us/sample - loss: 0.3915 - accuracy: 0.8630 - val_loss: 0.3601 - val_accuracy: 0.8754\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, add BN before activation function\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 5s 93us/sample - loss: 1.0334 - accuracy: 0.6755 - val_loss: 0.6738 - val_accuracy: 0.7832\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.6761 - accuracy: 0.7821 - val_loss: 0.5562 - val_accuracy: 0.8194\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.5929 - accuracy: 0.8057 - val_loss: 0.5006 - val_accuracy: 0.8370\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 5s 84us/sample - loss: 0.5467 - accuracy: 0.8160 - val_loss: 0.4652 - val_accuracy: 0.8454\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.5114 - accuracy: 0.8270 - val_loss: 0.4427 - val_accuracy: 0.8518\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 5s 84us/sample - loss: 0.4903 - accuracy: 0.8333 - val_loss: 0.4264 - val_accuracy: 0.8544\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 5s 84us/sample - loss: 0.4723 - accuracy: 0.8377 - val_loss: 0.4127 - val_accuracy: 0.8570\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 5s 84us/sample - loss: 0.4573 - accuracy: 0.8427 - val_loss: 0.4032 - val_accuracy: 0.8612\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.4433 - accuracy: 0.8470 - val_loss: 0.3943 - val_accuracy: 0.8636\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.4332 - accuracy: 0.8515 - val_loss: 0.3874 - val_accuracy: 0.8662\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we split the fashion MNIST training set:\n",
    "\n",
    "1) X_train_A: all items except for sandals and shirts (classes 5 and 6).\n",
    "\n",
    "2) X_train_B: a smaller set of 200 images of sandals or shirts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43986, 28, 28)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 28, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 5, 7, 7, 7, 4, 4, 3, 4, 0, 1, 6, 3, 4, 3, 2, 6, 5, 3, 4, 5,\n",
       "       1, 3, 4, 2, 0, 6, 7, 1], dtype=uint8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_A[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_B[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43986 samples, validate on 4014 samples\n",
      "Epoch 1/20\n",
      "43986/43986 [==============================] - 3s 66us/sample - loss: 0.5902 - accuracy: 0.8130 - val_loss: 0.3782 - val_accuracy: 0.8690\n",
      "Epoch 2/20\n",
      "43986/43986 [==============================] - 3s 60us/sample - loss: 0.3517 - accuracy: 0.8784 - val_loss: 0.3374 - val_accuracy: 0.8837\n",
      "Epoch 3/20\n",
      "43986/43986 [==============================] - 3s 60us/sample - loss: 0.3162 - accuracy: 0.8897 - val_loss: 0.3017 - val_accuracy: 0.8959\n",
      "Epoch 4/20\n",
      "43986/43986 [==============================] - 3s 60us/sample - loss: 0.2969 - accuracy: 0.8975 - val_loss: 0.2912 - val_accuracy: 0.9021\n",
      "Epoch 5/20\n",
      "43986/43986 [==============================] - 3s 60us/sample - loss: 0.2831 - accuracy: 0.9026 - val_loss: 0.2820 - val_accuracy: 0.9018\n",
      "Epoch 6/20\n",
      "43986/43986 [==============================] - 3s 60us/sample - loss: 0.2726 - accuracy: 0.9067 - val_loss: 0.2738 - val_accuracy: 0.9068\n",
      "Epoch 7/20\n",
      "43986/43986 [==============================] - 3s 60us/sample - loss: 0.2645 - accuracy: 0.9096 - val_loss: 0.2651 - val_accuracy: 0.9083\n",
      "Epoch 8/20\n",
      "43986/43986 [==============================] - 3s 60us/sample - loss: 0.2578 - accuracy: 0.9118 - val_loss: 0.2580 - val_accuracy: 0.9128\n",
      "Epoch 9/20\n",
      "43986/43986 [==============================] - 3s 59us/sample - loss: 0.2517 - accuracy: 0.9137 - val_loss: 0.2579 - val_accuracy: 0.9138\n",
      "Epoch 10/20\n",
      "43986/43986 [==============================] - 3s 58us/sample - loss: 0.2466 - accuracy: 0.9152 - val_loss: 0.2522 - val_accuracy: 0.9150\n",
      "Epoch 11/20\n",
      "43986/43986 [==============================] - 3s 58us/sample - loss: 0.2420 - accuracy: 0.9178 - val_loss: 0.2490 - val_accuracy: 0.9165\n",
      "Epoch 12/20\n",
      "43986/43986 [==============================] - 3s 59us/sample - loss: 0.2381 - accuracy: 0.9191 - val_loss: 0.2456 - val_accuracy: 0.9178\n",
      "Epoch 13/20\n",
      "43986/43986 [==============================] - 3s 61us/sample - loss: 0.2348 - accuracy: 0.9197 - val_loss: 0.2449 - val_accuracy: 0.9190\n",
      "Epoch 14/20\n",
      "43986/43986 [==============================] - 3s 59us/sample - loss: 0.2312 - accuracy: 0.9205 - val_loss: 0.2431 - val_accuracy: 0.9170\n",
      "Epoch 15/20\n",
      "43986/43986 [==============================] - 3s 58us/sample - loss: 0.2282 - accuracy: 0.9222 - val_loss: 0.2431 - val_accuracy: 0.9180\n",
      "Epoch 16/20\n",
      "43986/43986 [==============================] - 3s 59us/sample - loss: 0.2255 - accuracy: 0.9230 - val_loss: 0.2409 - val_accuracy: 0.9148\n",
      "Epoch 17/20\n",
      "43986/43986 [==============================] - 3s 58us/sample - loss: 0.2228 - accuracy: 0.9232 - val_loss: 0.2370 - val_accuracy: 0.9178\n",
      "Epoch 18/20\n",
      "43986/43986 [==============================] - 3s 60us/sample - loss: 0.2201 - accuracy: 0.9245 - val_loss: 0.2430 - val_accuracy: 0.9168\n",
      "Epoch 19/20\n",
      "43986/43986 [==============================] - 3s 60us/sample - loss: 0.2177 - accuracy: 0.9252 - val_loss: 0.2605 - val_accuracy: 0.9053\n",
      "Epoch 20/20\n",
      "43986/43986 [==============================] - 3s 60us/sample - loss: 0.2158 - accuracy: 0.9266 - val_loss: 0.2329 - val_accuracy: 0.9210\n"
     ]
    }
   ],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 986 samples\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.9509 - accuracy: 0.4800 - val_loss: 0.6533 - val_accuracy: 0.5568\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 0s 328us/sample - loss: 0.5837 - accuracy: 0.7100 - val_loss: 0.4825 - val_accuracy: 0.8479\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 0s 326us/sample - loss: 0.4527 - accuracy: 0.8750 - val_loss: 0.4097 - val_accuracy: 0.8945\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 0s 310us/sample - loss: 0.3869 - accuracy: 0.9050 - val_loss: 0.3630 - val_accuracy: 0.9209\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 0s 288us/sample - loss: 0.3404 - accuracy: 0.9300 - val_loss: 0.3302 - val_accuracy: 0.9280\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 0s 327us/sample - loss: 0.3073 - accuracy: 0.9350 - val_loss: 0.3026 - val_accuracy: 0.9381\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 0s 305us/sample - loss: 0.2797 - accuracy: 0.9400 - val_loss: 0.2790 - val_accuracy: 0.9452\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 0s 282us/sample - loss: 0.2554 - accuracy: 0.9450 - val_loss: 0.2595 - val_accuracy: 0.9473\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 0s 283us/sample - loss: 0.2355 - accuracy: 0.9600 - val_loss: 0.2439 - val_accuracy: 0.9493\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 0s 291us/sample - loss: 0.2187 - accuracy: 0.9650 - val_loss: 0.2293 - val_accuracy: 0.9523\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 0s 280us/sample - loss: 0.2041 - accuracy: 0.9650 - val_loss: 0.2162 - val_accuracy: 0.9544\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 0s 295us/sample - loss: 0.1906 - accuracy: 0.9650 - val_loss: 0.2049 - val_accuracy: 0.9574\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 0s 288us/sample - loss: 0.1791 - accuracy: 0.9700 - val_loss: 0.1946 - val_accuracy: 0.9594\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 0s 218us/sample - loss: 0.1686 - accuracy: 0.9750 - val_loss: 0.1856 - val_accuracy: 0.9615\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 0s 254us/sample - loss: 0.1591 - accuracy: 0.9750 - val_loss: 0.1765 - val_accuracy: 0.9655\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 0s 325us/sample - loss: 0.1502 - accuracy: 0.9900 - val_loss: 0.1695 - val_accuracy: 0.9655\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 0s 297us/sample - loss: 0.1424 - accuracy: 0.9900 - val_loss: 0.1624 - val_accuracy: 0.9686\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 0s 290us/sample - loss: 0.1351 - accuracy: 0.9900 - val_loss: 0.1567 - val_accuracy: 0.9686\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 0s 287us/sample - loss: 0.1290 - accuracy: 0.9900 - val_loss: 0.1513 - val_accuracy: 0.9696\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 0s 298us/sample - loss: 0.1229 - accuracy: 0.9900 - val_loss: 0.1450 - val_accuracy: 0.9696\n"
     ]
    }
   ],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 300)               235200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 100)               30000     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 270,946\n",
      "Trainable params: 268,578\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To have an unchanged version of model_A during supervised learning, clone it and its weights:\n",
    "\n",
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 986 samples\n",
      "Epoch 1/4\n",
      "200/200 [==============================] - 1s 4ms/sample - loss: 0.5619 - accuracy: 0.6700 - val_loss: 0.5676 - val_accuracy: 0.6521\n",
      "Epoch 2/4\n",
      "200/200 [==============================] - 0s 322us/sample - loss: 0.5249 - accuracy: 0.7200 - val_loss: 0.5343 - val_accuracy: 0.6937\n",
      "Epoch 3/4\n",
      "200/200 [==============================] - 0s 267us/sample - loss: 0.4922 - accuracy: 0.7400 - val_loss: 0.5044 - val_accuracy: 0.7181\n",
      "Epoch 4/4\n",
      "200/200 [==============================] - 0s 273us/sample - loss: 0.4628 - accuracy: 0.7600 - val_loss: 0.4778 - val_accuracy: 0.7394\n"
     ]
    }
   ],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 986 samples\n",
      "Epoch 1/16\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.3865 - accuracy: 0.8250 - val_loss: 0.3362 - val_accuracy: 0.8682\n",
      "Epoch 2/16\n",
      "200/200 [==============================] - 0s 321us/sample - loss: 0.2701 - accuracy: 0.9300 - val_loss: 0.2611 - val_accuracy: 0.9280\n",
      "Epoch 3/16\n",
      "200/200 [==============================] - 0s 305us/sample - loss: 0.2081 - accuracy: 0.9650 - val_loss: 0.2151 - val_accuracy: 0.9513\n",
      "Epoch 4/16\n",
      "200/200 [==============================] - 0s 300us/sample - loss: 0.1694 - accuracy: 0.9800 - val_loss: 0.1841 - val_accuracy: 0.9635\n",
      "Epoch 5/16\n",
      "200/200 [==============================] - 0s 312us/sample - loss: 0.1427 - accuracy: 0.9800 - val_loss: 0.1602 - val_accuracy: 0.9716\n",
      "Epoch 6/16\n",
      "200/200 [==============================] - 0s 299us/sample - loss: 0.1219 - accuracy: 0.9850 - val_loss: 0.1424 - val_accuracy: 0.9797\n",
      "Epoch 7/16\n",
      "200/200 [==============================] - 0s 299us/sample - loss: 0.1066 - accuracy: 0.9950 - val_loss: 0.1294 - val_accuracy: 0.9828\n",
      "Epoch 8/16\n",
      "200/200 [==============================] - 0s 298us/sample - loss: 0.0952 - accuracy: 0.9950 - val_loss: 0.1187 - val_accuracy: 0.9848\n",
      "Epoch 9/16\n",
      "200/200 [==============================] - 0s 303us/sample - loss: 0.0858 - accuracy: 0.9950 - val_loss: 0.1100 - val_accuracy: 0.9848\n",
      "Epoch 10/16\n",
      "200/200 [==============================] - 0s 293us/sample - loss: 0.0782 - accuracy: 1.0000 - val_loss: 0.1027 - val_accuracy: 0.9878\n",
      "Epoch 11/16\n",
      "200/200 [==============================] - 0s 304us/sample - loss: 0.0720 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9888\n",
      "Epoch 12/16\n",
      "200/200 [==============================] - 0s 298us/sample - loss: 0.0665 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9888\n",
      "Epoch 13/16\n",
      "200/200 [==============================] - 0s 328us/sample - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9899\n",
      "Epoch 14/16\n",
      "200/200 [==============================] - 0s 297us/sample - loss: 0.0575 - accuracy: 1.0000 - val_loss: 0.0819 - val_accuracy: 0.9899\n",
      "Epoch 15/16\n",
      "200/200 [==============================] - 0s 312us/sample - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9899\n",
      "Epoch 16/16\n",
      "200/200 [==============================] - 0s 304us/sample - loss: 0.0505 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9899\n"
     ]
    }
   ],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 36us/sample - loss: 0.1426 - accuracy: 0.9695\n",
      "2000/2000 [==============================] - 0s 39us/sample - loss: 0.0697 - accuracy: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.066669845584086"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ , B_accuracy = model_B.evaluate(X_test_B, y_test_B);\n",
    "_ , B_on_A_accuracy = model_B_on_A.evaluate(X_test_B, y_test_B);\n",
    "\n",
    "(1 - B_accuracy) / (1 - B_on_A_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the error rate dropped by a factor of 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Momentum optimization\n",
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "\n",
    "# Nesterov Accelerated Gradient\n",
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "# AdaGrad\n",
    "optimizer = keras.optimizers.Adagrad(lr=0.001)\n",
    "\n",
    "# RMSProp\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)\n",
    "\n",
    "# Adam Optimization\n",
    "optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "# Adamax Optimization\n",
    "optimizer = keras.optimizers.Adamax(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "# Nadam Optimization\n",
    "optimizer = keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 5s 92us/sample - loss: 0.4723 - accuracy: 0.8361 - val_loss: 0.3830 - val_accuracy: 0.8642\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.3454 - accuracy: 0.8729 - val_loss: 0.3383 - val_accuracy: 0.8780\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 4s 72us/sample - loss: 0.3056 - accuracy: 0.8876 - val_loss: 0.3485 - val_accuracy: 0.8742\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 4s 72us/sample - loss: 0.2796 - accuracy: 0.8957 - val_loss: 0.3492 - val_accuracy: 0.8782\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 5s 82us/sample - loss: 0.2598 - accuracy: 0.9027 - val_loss: 0.3384 - val_accuracy: 0.8862\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 4s 79us/sample - loss: 0.2404 - accuracy: 0.9099 - val_loss: 0.3805 - val_accuracy: 0.8752\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 5s 83us/sample - loss: 0.2242 - accuracy: 0.9151 - val_loss: 0.3415 - val_accuracy: 0.8890\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 5s 84us/sample - loss: 0.2046 - accuracy: 0.9234 - val_loss: 0.3592 - val_accuracy: 0.8868\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.1965 - accuracy: 0.9270 - val_loss: 0.3835 - val_accuracy: 0.8858\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.1840 - accuracy: 0.9308 - val_loss: 0.3724 - val_accuracy: 0.8842\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 5s 86us/sample - loss: 0.1715 - accuracy: 0.9357 - val_loss: 0.4136 - val_accuracy: 0.8840\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 5s 88us/sample - loss: 0.1631 - accuracy: 0.9394 - val_loss: 0.4205 - val_accuracy: 0.8824\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 5s 86us/sample - loss: 0.1531 - accuracy: 0.9435 - val_loss: 0.4236 - val_accuracy: 0.8878\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 5s 88us/sample - loss: 0.1465 - accuracy: 0.9464 - val_loss: 0.4357 - val_accuracy: 0.8898\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 5s 90us/sample - loss: 0.1379 - accuracy: 0.9495 - val_loss: 0.4399 - val_accuracy: 0.8914\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.1308 - accuracy: 0.9529 - val_loss: 0.4757 - val_accuracy: 0.8876\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.1244 - accuracy: 0.9540 - val_loss: 0.5286 - val_accuracy: 0.8882\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.1189 - accuracy: 0.9569 - val_loss: 0.5000 - val_accuracy: 0.8996\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 5s 84us/sample - loss: 0.1139 - accuracy: 0.9585 - val_loss: 0.5494 - val_accuracy: 0.8812\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 5s 92us/sample - loss: 0.1115 - accuracy: 0.9591 - val_loss: 0.5637 - val_accuracy: 0.8920\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 5s 83us/sample - loss: 0.1066 - accuracy: 0.9624 - val_loss: 0.5365 - val_accuracy: 0.8928\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.0983 - accuracy: 0.9650 - val_loss: 0.5683 - val_accuracy: 0.8926\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 5s 88us/sample - loss: 0.1014 - accuracy: 0.9642 - val_loss: 0.5755 - val_accuracy: 0.8874\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 5s 84us/sample - loss: 0.0931 - accuracy: 0.9665 - val_loss: 0.6079 - val_accuracy: 0.8886\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 5s 97us/sample - loss: 0.0968 - accuracy: 0.9659 - val_loss: 0.5967 - val_accuracy: 0.8964\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The schedule function can take epoch and lr as arguments:\n",
    "\n",
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 5s 92us/sample - loss: 0.8582 - accuracy: 0.7551 - val_loss: 0.6840 - val_accuracy: 0.7208\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 4s 79us/sample - loss: 0.6948 - accuracy: 0.7927 - val_loss: 0.5689 - val_accuracy: 0.8076\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 4s 77us/sample - loss: 0.6328 - accuracy: 0.8084 - val_loss: 0.6285 - val_accuracy: 0.8274\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.5837 - accuracy: 0.8218 - val_loss: 0.6375 - val_accuracy: 0.8396\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 5s 90us/sample - loss: 0.4894 - accuracy: 0.8475 - val_loss: 0.6127 - val_accuracy: 0.8134\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.4659 - accuracy: 0.8546 - val_loss: 0.4972 - val_accuracy: 0.8422\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.4250 - accuracy: 0.8651 - val_loss: 0.5517 - val_accuracy: 0.8540\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 5s 86us/sample - loss: 0.3952 - accuracy: 0.8735 - val_loss: 0.4771 - val_accuracy: 0.8502\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.3592 - accuracy: 0.8824 - val_loss: 0.4554 - val_accuracy: 0.8752\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.3325 - accuracy: 0.8909 - val_loss: 0.4832 - val_accuracy: 0.8776\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 5s 88us/sample - loss: 0.3189 - accuracy: 0.8943 - val_loss: 0.4534 - val_accuracy: 0.8650\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.2964 - accuracy: 0.9029 - val_loss: 0.4525 - val_accuracy: 0.8738\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 5s 91us/sample - loss: 0.2737 - accuracy: 0.9076 - val_loss: 0.5012 - val_accuracy: 0.8790\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 5s 93us/sample - loss: 0.2573 - accuracy: 0.9128 - val_loss: 0.4691 - val_accuracy: 0.8836\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 5s 90us/sample - loss: 0.2386 - accuracy: 0.9194 - val_loss: 0.4929 - val_accuracy: 0.8760\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 5s 91us/sample - loss: 0.2201 - accuracy: 0.9250 - val_loss: 0.4625 - val_accuracy: 0.8834\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 5s 93us/sample - loss: 0.2063 - accuracy: 0.9308 - val_loss: 0.4895 - val_accuracy: 0.8860\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.1972 - accuracy: 0.9339 - val_loss: 0.4869 - val_accuracy: 0.8818\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 5s 94us/sample - loss: 0.1829 - accuracy: 0.9370 - val_loss: 0.4954 - val_accuracy: 0.8880\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 5s 86us/sample - loss: 0.1668 - accuracy: 0.9429 - val_loss: 0.5044 - val_accuracy: 0.8884\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 5s 88us/sample - loss: 0.1571 - accuracy: 0.9465 - val_loss: 0.5319 - val_accuracy: 0.8880\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 5s 93us/sample - loss: 0.1485 - accuracy: 0.9511 - val_loss: 0.5559 - val_accuracy: 0.8876\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.1394 - accuracy: 0.9535 - val_loss: 0.5569 - val_accuracy: 0.8838\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 5s 92us/sample - loss: 0.1328 - accuracy: 0.9553 - val_loss: 0.5997 - val_accuracy: 0.8864\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 4s 82us/sample - loss: 0.1241 - accuracy: 0.9591 - val_loss: 0.6007 - val_accuracy: 0.8848\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "\n",
    "Its function can have both lr and epoch as arguments similarly.\n",
    "In this case, take care of the initial values of lr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch, lr):\n",
    "    return lr * 0.1**(1 / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 5s 88us/sample - loss: 0.7706 - accuracy: 0.7745 - val_loss: 0.7471 - val_accuracy: 0.7364\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 4s 78us/sample - loss: 0.6275 - accuracy: 0.8100 - val_loss: 0.6246 - val_accuracy: 0.8222\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 4s 80us/sample - loss: 0.5656 - accuracy: 0.8240 - val_loss: 0.5913 - val_accuracy: 0.8280\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 4s 80us/sample - loss: 0.4938 - accuracy: 0.8439 - val_loss: 0.7106 - val_accuracy: 0.7978\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 4s 78us/sample - loss: 0.4663 - accuracy: 0.8517 - val_loss: 0.5165 - val_accuracy: 0.8570\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.4319 - accuracy: 0.8621 - val_loss: 0.5376 - val_accuracy: 0.8590\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.3974 - accuracy: 0.8710 - val_loss: 0.4812 - val_accuracy: 0.8590\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.3636 - accuracy: 0.8813 - val_loss: 0.4603 - val_accuracy: 0.8682\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 5s 88us/sample - loss: 0.3293 - accuracy: 0.8899 - val_loss: 0.4223 - val_accuracy: 0.8758\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 5s 90us/sample - loss: 0.3041 - accuracy: 0.8981 - val_loss: 0.4338 - val_accuracy: 0.8750\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.2993 - accuracy: 0.8999 - val_loss: 0.4130 - val_accuracy: 0.8838\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 5s 93us/sample - loss: 0.2641 - accuracy: 0.9097 - val_loss: 0.4753 - val_accuracy: 0.8796\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 6s 102us/sample - loss: 0.2476 - accuracy: 0.9166 - val_loss: 0.4695 - val_accuracy: 0.8794\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 6s 101us/sample - loss: 0.2332 - accuracy: 0.9197 - val_loss: 0.4774 - val_accuracy: 0.8786\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 5s 92us/sample - loss: 0.2143 - accuracy: 0.9276 - val_loss: 0.4755 - val_accuracy: 0.8850\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 5s 92us/sample - loss: 0.1991 - accuracy: 0.9326 - val_loss: 0.4608 - val_accuracy: 0.8882\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 5s 86us/sample - loss: 0.1824 - accuracy: 0.9378 - val_loss: 0.4511 - val_accuracy: 0.8892\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 5s 90us/sample - loss: 0.1720 - accuracy: 0.9407 - val_loss: 0.4604 - val_accuracy: 0.8858\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 5s 91us/sample - loss: 0.1572 - accuracy: 0.9461 - val_loss: 0.4798 - val_accuracy: 0.8846\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 5s 99us/sample - loss: 0.1438 - accuracy: 0.9514 - val_loss: 0.4836 - val_accuracy: 0.8908\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 5s 98us/sample - loss: 0.1365 - accuracy: 0.9549 - val_loss: 0.5158 - val_accuracy: 0.8918\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 6s 102us/sample - loss: 0.1238 - accuracy: 0.9589 - val_loss: 0.5425 - val_accuracy: 0.8884\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.1155 - accuracy: 0.9624 - val_loss: 0.5530 - val_accuracy: 0.8872\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 5s 90us/sample - loss: 0.1080 - accuracy: 0.9652 - val_loss: 0.5890 - val_accuracy: 0.8850\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.1005 - accuracy: 0.9683 - val_loss: 0.6207 - val_accuracy: 0.8904\n"
     ]
    }
   ],
   "source": [
    "# If lr is updated at each batch:\n",
    "\n",
    "K = keras.backend\n",
    "\n",
    "class ExponentialDecay(keras.callbacks.Callback):\n",
    "    def __init__(self, s=40000):\n",
    "        super().__init__()\n",
    "        self.s = s\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        lr = K.get_value(self.model.optimizer.lr)\n",
    "        K.set_value(self.model.optimizer.lr, lr * 0.1**(1 / s))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.lr)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "lr0 = 0.01\n",
    "optimizer = keras.optimizers.Nadam(lr=lr0)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "\n",
    "s = 20 * len(X_train) // 32     # number of steps in 20 epochs (batch size = 32)\n",
    "exp_decay = ExponentialDecay(s)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[exp_decay])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Piecewise Constant Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant_fn(epoch):   # just for clarification\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif epoch < 15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001\n",
    "\n",
    "\n",
    "def piecewise_constant(boundaries, values):\n",
    "    boundaries = np.array([0] + boundaries)\n",
    "    values = np.array(values)\n",
    "    def piecewise_constant_fn(epoch):\n",
    "        return values[np.argmax(boundaries > epoch) - 1]\n",
    "    return piecewise_constant_fn\n",
    "\n",
    "piecewise_constant_fn = piecewise_constant([5, 15], [0.01, 0.005, 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 4s 78us/sample - loss: 0.8381 - accuracy: 0.7606 - val_loss: 1.0661 - val_accuracy: 0.7208\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.7781 - accuracy: 0.7725 - val_loss: 0.8141 - val_accuracy: 0.7558\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 4s 68us/sample - loss: 0.8917 - accuracy: 0.7417 - val_loss: 0.8621 - val_accuracy: 0.7546\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 4s 68us/sample - loss: 0.9439 - accuracy: 0.7196 - val_loss: 1.0402 - val_accuracy: 0.7100\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 4s 68us/sample - loss: 0.8538 - accuracy: 0.7262 - val_loss: 0.9904 - val_accuracy: 0.8032\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 4s 78us/sample - loss: 0.5831 - accuracy: 0.8199 - val_loss: 0.7717 - val_accuracy: 0.8092\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 4s 75us/sample - loss: 0.5094 - accuracy: 0.8429 - val_loss: 0.6582 - val_accuracy: 0.8268\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 4s 77us/sample - loss: 0.5112 - accuracy: 0.8425 - val_loss: 0.6064 - val_accuracy: 0.8370\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 4s 77us/sample - loss: 0.4922 - accuracy: 0.8510 - val_loss: 0.5471 - val_accuracy: 0.8452\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 4s 74us/sample - loss: 0.4683 - accuracy: 0.8573 - val_loss: 0.6127 - val_accuracy: 0.8296\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.4837 - accuracy: 0.8537 - val_loss: 0.6558 - val_accuracy: 0.8432\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 4s 74us/sample - loss: 0.4603 - accuracy: 0.8594 - val_loss: 0.6506 - val_accuracy: 0.8418\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 5s 82us/sample - loss: 0.4827 - accuracy: 0.8563 - val_loss: 0.6616 - val_accuracy: 0.8332\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 5s 83us/sample - loss: 0.4545 - accuracy: 0.8625 - val_loss: 0.6205 - val_accuracy: 0.8558\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 5s 83us/sample - loss: 0.4534 - accuracy: 0.8675 - val_loss: 0.7510 - val_accuracy: 0.8388\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 4s 78us/sample - loss: 0.3243 - accuracy: 0.8959 - val_loss: 0.5811 - val_accuracy: 0.8676\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.2916 - accuracy: 0.9043 - val_loss: 0.5924 - val_accuracy: 0.8742\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 4s 78us/sample - loss: 0.2788 - accuracy: 0.9081 - val_loss: 0.5742 - val_accuracy: 0.8730\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 5s 83us/sample - loss: 0.2700 - accuracy: 0.9114 - val_loss: 0.5844 - val_accuracy: 0.8706\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.2639 - accuracy: 0.9129 - val_loss: 0.5960 - val_accuracy: 0.8738\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.2481 - accuracy: 0.9156 - val_loss: 0.5800 - val_accuracy: 0.8714\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.2302 - accuracy: 0.9163 - val_loss: 0.6163 - val_accuracy: 0.8710\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 4s 80us/sample - loss: 0.2166 - accuracy: 0.9193 - val_loss: 0.5836 - val_accuracy: 0.8750\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 4s 78us/sample - loss: 0.2113 - accuracy: 0.9206 - val_loss: 0.5743 - val_accuracy: 0.8746\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 4s 77us/sample - loss: 0.2027 - accuracy: 0.9254 - val_loss: 0.6463 - val_accuracy: 0.8824\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(piecewise_constant_fn)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, [piecewise_constant_fn(epoch) for epoch in history.epoch], \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Piecewise Constant Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.5902 - accuracy: 0.8081 - val_loss: 0.4767 - val_accuracy: 0.8476\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.5100 - accuracy: 0.8367 - val_loss: 0.4400 - val_accuracy: 0.8566\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.4976 - accuracy: 0.8449 - val_loss: 0.4885 - val_accuracy: 0.8360\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 3s 57us/sample - loss: 0.5116 - accuracy: 0.8478 - val_loss: 0.6338 - val_accuracy: 0.8480\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.5328 - accuracy: 0.8478 - val_loss: 0.7667 - val_accuracy: 0.8330\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.5428 - accuracy: 0.8501 - val_loss: 0.6829 - val_accuracy: 0.8536\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.5374 - accuracy: 0.8519 - val_loss: 0.6139 - val_accuracy: 0.8482\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.3028 - accuracy: 0.8938 - val_loss: 0.3939 - val_accuracy: 0.8800\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.2510 - accuracy: 0.9079 - val_loss: 0.3783 - val_accuracy: 0.8796\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.2288 - accuracy: 0.9159 - val_loss: 0.3736 - val_accuracy: 0.8908\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.2191 - accuracy: 0.9194 - val_loss: 0.4143 - val_accuracy: 0.8848\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.2070 - accuracy: 0.9231 - val_loss: 0.4000 - val_accuracy: 0.8904\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 3s 63us/sample - loss: 0.1954 - accuracy: 0.9276 - val_loss: 0.4288 - val_accuracy: 0.8812\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.1910 - accuracy: 0.9304 - val_loss: 0.4154 - val_accuracy: 0.8948\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.1785 - accuracy: 0.9331 - val_loss: 0.4434 - val_accuracy: 0.8802\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 3s 57us/sample - loss: 0.1223 - accuracy: 0.9513 - val_loss: 0.4105 - val_accuracy: 0.8970\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.1052 - accuracy: 0.9589 - val_loss: 0.4251 - val_accuracy: 0.8926\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.0980 - accuracy: 0.9617 - val_loss: 0.4530 - val_accuracy: 0.8944\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 3s 57us/sample - loss: 0.0919 - accuracy: 0.9638 - val_loss: 0.4899 - val_accuracy: 0.8904\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.0839 - accuracy: 0.9669 - val_loss: 0.4579 - val_accuracy: 0.8938\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 3s 57us/sample - loss: 0.0647 - accuracy: 0.9756 - val_loss: 0.4828 - val_accuracy: 0.8950\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 4s 68us/sample - loss: 0.0594 - accuracy: 0.9786 - val_loss: 0.4942 - val_accuracy: 0.8940\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 3s 62us/sample - loss: 0.0557 - accuracy: 0.9799 - val_loss: 0.5075 - val_accuracy: 0.8974\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 3s 62us/sample - loss: 0.0526 - accuracy: 0.9815 - val_loss: 0.5214 - val_accuracy: 0.8944\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.0499 - accuracy: 0.9822 - val_loss: 0.5349 - val_accuracy: 0.8970\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(lr=0.02, momentum=0.9)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history[\"lr\"], \"bo-\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\", color='b')\n",
    "plt.tick_params('y', colors='b')\n",
    "plt.gca().set_xlim(0, n_epochs - 1)\n",
    "plt.grid(True)\n",
    "\n",
    "ax2 = plt.gca().twinx()\n",
    "ax2.plot(history.epoch, history.history[\"val_loss\"], \"r^-\")\n",
    "ax2.set_ylabel('Validation Loss', color='r')\n",
    "ax2.tick_params('y', colors='r')\n",
    "\n",
    "plt.title(\"Reduce LR on Plateau\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.keras schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 4s 75us/sample - loss: 0.4873 - accuracy: 0.8296 - val_loss: 0.4139 - val_accuracy: 0.8554\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.3829 - accuracy: 0.8645 - val_loss: 0.3771 - val_accuracy: 0.8698\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.3495 - accuracy: 0.8762 - val_loss: 0.3696 - val_accuracy: 0.8724\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.3275 - accuracy: 0.8829 - val_loss: 0.3539 - val_accuracy: 0.8752\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.3103 - accuracy: 0.8897 - val_loss: 0.3457 - val_accuracy: 0.8786\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.2972 - accuracy: 0.8944 - val_loss: 0.3409 - val_accuracy: 0.8804\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.2859 - accuracy: 0.8986 - val_loss: 0.3354 - val_accuracy: 0.8832\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.2768 - accuracy: 0.9020 - val_loss: 0.3320 - val_accuracy: 0.8834\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.2686 - accuracy: 0.9045 - val_loss: 0.3282 - val_accuracy: 0.8860\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.2613 - accuracy: 0.9074 - val_loss: 0.3305 - val_accuracy: 0.8836\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.2556 - accuracy: 0.9096 - val_loss: 0.3262 - val_accuracy: 0.8868\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.2503 - accuracy: 0.9115 - val_loss: 0.3246 - val_accuracy: 0.8868\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.2457 - accuracy: 0.9131 - val_loss: 0.3242 - val_accuracy: 0.8860\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.2416 - accuracy: 0.9144 - val_loss: 0.3235 - val_accuracy: 0.8860\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 3s 57us/sample - loss: 0.2380 - accuracy: 0.9167 - val_loss: 0.3197 - val_accuracy: 0.8876\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 3s 57us/sample - loss: 0.2347 - accuracy: 0.9171 - val_loss: 0.3208 - val_accuracy: 0.8870\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.2321 - accuracy: 0.9188 - val_loss: 0.3183 - val_accuracy: 0.8888\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.2292 - accuracy: 0.9193 - val_loss: 0.3208 - val_accuracy: 0.8884\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.2272 - accuracy: 0.9203 - val_loss: 0.3196 - val_accuracy: 0.8888\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 3s 63us/sample - loss: 0.2252 - accuracy: 0.9214 - val_loss: 0.3180 - val_accuracy: 0.8886\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 3s 62us/sample - loss: 0.2235 - accuracy: 0.9215 - val_loss: 0.3173 - val_accuracy: 0.8898\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 3s 64us/sample - loss: 0.2218 - accuracy: 0.9229 - val_loss: 0.3173 - val_accuracy: 0.8900\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.2204 - accuracy: 0.9226 - val_loss: 0.3170 - val_accuracy: 0.8892\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 3s 62us/sample - loss: 0.2191 - accuracy: 0.9240 - val_loss: 0.3176 - val_accuracy: 0.8902\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.2182 - accuracy: 0.9242 - val_loss: 0.3168 - val_accuracy: 0.8902\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "optimizer = keras.optimizers.SGD(learning_rate)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=[5. * n_steps_per_epoch, 15. * n_steps_per_epoch],\n",
    "    values=[0.01, 0.005, 0.001])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Cycle scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see the acceptable max of lr.\n",
    "\n",
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)\n",
    "\n",
    "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = len(X) // batch_size * epochs\n",
    "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.lr)\n",
    "    K.set_value(model.optimizer.lr, min_rate)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
    "                        callbacks=[exp_lr])\n",
    "    K.set_value(model.optimizer.lr, init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses\n",
    "\n",
    "def plot_lr_vs_loss(rates, losses):\n",
    "    plt.plot(rates, losses)\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.hlines(min(losses), min(rates), max(rates))\n",
    "    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples\n",
      "55000/55000 [==============================] - 2s 28us/sample - loss: nan - accuracy: 0.3881           \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
    "plot_lr_vs_loss(rates, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "            rate = max(rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.lr, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 1s 26us/sample - loss: 0.6576 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.8300\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 1s 25us/sample - loss: 0.4587 - accuracy: 0.8387 - val_loss: 0.4316 - val_accuracy: 0.8490\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.4119 - accuracy: 0.8560 - val_loss: 0.4118 - val_accuracy: 0.8578\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.3842 - accuracy: 0.8656 - val_loss: 0.3919 - val_accuracy: 0.8636\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.3636 - accuracy: 0.8709 - val_loss: 0.3739 - val_accuracy: 0.8710\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.3460 - accuracy: 0.8765 - val_loss: 0.3742 - val_accuracy: 0.8694\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.3312 - accuracy: 0.8819 - val_loss: 0.3758 - val_accuracy: 0.8646\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.3193 - accuracy: 0.8845 - val_loss: 0.3580 - val_accuracy: 0.8748\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.3057 - accuracy: 0.8903 - val_loss: 0.3470 - val_accuracy: 0.8826\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2943 - accuracy: 0.8935 - val_loss: 0.4018 - val_accuracy: 0.8552\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2846 - accuracy: 0.8959 - val_loss: 0.3448 - val_accuracy: 0.8818\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2720 - accuracy: 0.9014 - val_loss: 0.3347 - val_accuracy: 0.8816\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.2537 - accuracy: 0.9093 - val_loss: 0.3390 - val_accuracy: 0.8804\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2420 - accuracy: 0.9129 - val_loss: 0.3327 - val_accuracy: 0.8850\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.2290 - accuracy: 0.9173 - val_loss: 0.3240 - val_accuracy: 0.8840\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2169 - accuracy: 0.9221 - val_loss: 0.3339 - val_accuracy: 0.8858\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2068 - accuracy: 0.9265 - val_loss: 0.3207 - val_accuracy: 0.8874\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1978 - accuracy: 0.9299 - val_loss: 0.3187 - val_accuracy: 0.8894\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1894 - accuracy: 0.9330 - val_loss: 0.3271 - val_accuracy: 0.8852\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 1s 26us/sample - loss: 0.1820 - accuracy: 0.9376 - val_loss: 0.3192 - val_accuracy: 0.8906\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1757 - accuracy: 0.9392 - val_loss: 0.3161 - val_accuracy: 0.8948\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 1s 26us/sample - loss: 0.1702 - accuracy: 0.9416 - val_loss: 0.3178 - val_accuracy: 0.8930\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 1s 26us/sample - loss: 0.1657 - accuracy: 0.9440 - val_loss: 0.3169 - val_accuracy: 0.8950\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 2s 30us/sample - loss: 0.1629 - accuracy: 0.9450 - val_loss: 0.3167 - val_accuracy: 0.8948\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 2s 28us/sample - loss: 0.1612 - accuracy: 0.9465 - val_loss: 0.3171 - val_accuracy: 0.8950\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 25\n",
    "onecycle = OneCycleScheduler(len(X_train) // batch_size * n_epochs, max_rate=0.05)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### l1 and l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 5s 83us/sample - loss: 1.6006 - accuracy: 0.8129 - val_loss: 0.7374 - val_accuracy: 0.8236\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 4s 73us/sample - loss: 0.7179 - accuracy: 0.8265 - val_loss: 0.6905 - val_accuracy: 0.8356\n"
     ]
    }
   ],
   "source": [
    "# E.g.: use functools to make it more neat\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                           activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    RegularizedDense(300),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 5s 98us/sample - loss: 0.5856 - accuracy: 0.7992 - val_loss: 0.3908 - val_accuracy: 0.8570\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.4260 - accuracy: 0.8443 - val_loss: 0.3392 - val_accuracy: 0.8744\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.6655 - accuracy: 0.7581 - val_loss: 0.6729 - val_accuracy: 0.8266\n",
      "Epoch 2/20\n",
      "55000/55000 [==============================] - 5s 82us/sample - loss: 0.5528 - accuracy: 0.7969 - val_loss: 0.5881 - val_accuracy: 0.8392\n",
      "Epoch 3/20\n",
      "55000/55000 [==============================] - 5s 84us/sample - loss: 0.5256 - accuracy: 0.8061 - val_loss: 0.5299 - val_accuracy: 0.8434\n",
      "Epoch 4/20\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.5058 - accuracy: 0.8139 - val_loss: 0.4903 - val_accuracy: 0.8572\n",
      "Epoch 5/20\n",
      "55000/55000 [==============================] - 4s 80us/sample - loss: 0.4936 - accuracy: 0.8165 - val_loss: 0.4877 - val_accuracy: 0.8620\n",
      "Epoch 6/20\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.4774 - accuracy: 0.8221 - val_loss: 0.5181 - val_accuracy: 0.8586\n",
      "Epoch 7/20\n",
      "55000/55000 [==============================] - 5s 88us/sample - loss: 0.4711 - accuracy: 0.8262 - val_loss: 0.4523 - val_accuracy: 0.8674\n",
      "Epoch 8/20\n",
      "55000/55000 [==============================] - 5s 82us/sample - loss: 0.4640 - accuracy: 0.8277 - val_loss: 0.4919 - val_accuracy: 0.8516\n",
      "Epoch 9/20\n",
      "55000/55000 [==============================] - 5s 84us/sample - loss: 0.4551 - accuracy: 0.8314 - val_loss: 0.4348 - val_accuracy: 0.8658\n",
      "Epoch 10/20\n",
      "55000/55000 [==============================] - 5s 83us/sample - loss: 0.4506 - accuracy: 0.8329 - val_loss: 0.4409 - val_accuracy: 0.8620\n",
      "Epoch 11/20\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.4495 - accuracy: 0.8336 - val_loss: 0.4372 - val_accuracy: 0.8716\n",
      "Epoch 12/20\n",
      "55000/55000 [==============================] - 5s 86us/sample - loss: 0.4464 - accuracy: 0.8353 - val_loss: 0.4395 - val_accuracy: 0.8716\n",
      "Epoch 13/20\n",
      "55000/55000 [==============================] - 5s 84us/sample - loss: 0.4382 - accuracy: 0.8390 - val_loss: 0.4448 - val_accuracy: 0.8706\n",
      "Epoch 14/20\n",
      "55000/55000 [==============================] - 5s 84us/sample - loss: 0.4370 - accuracy: 0.8391 - val_loss: 0.4650 - val_accuracy: 0.8740\n",
      "Epoch 15/20\n",
      "55000/55000 [==============================] - 5s 86us/sample - loss: 0.4301 - accuracy: 0.8379 - val_loss: 0.4284 - val_accuracy: 0.8740\n",
      "Epoch 16/20\n",
      "55000/55000 [==============================] - 4s 82us/sample - loss: 0.4285 - accuracy: 0.8403 - val_loss: 0.4871 - val_accuracy: 0.8576\n",
      "Epoch 17/20\n",
      "55000/55000 [==============================] - 5s 83us/sample - loss: 0.4287 - accuracy: 0.8418 - val_loss: 0.4871 - val_accuracy: 0.8694\n",
      "Epoch 18/20\n",
      "55000/55000 [==============================] - 4s 80us/sample - loss: 0.4238 - accuracy: 0.8419 - val_loss: 0.4512 - val_accuracy: 0.8710\n",
      "Epoch 19/20\n",
      "55000/55000 [==============================] - 5s 84us/sample - loss: 0.4239 - accuracy: 0.8410 - val_loss: 0.4148 - val_accuracy: 0.8742\n",
      "Epoch 20/20\n",
      "55000/55000 [==============================] - 5s 88us/sample - loss: 0.4189 - accuracy: 0.8453 - val_loss: 0.4190 - val_accuracy: 0.8796\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 20\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MC Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer flatten_17 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_probas = np.stack([model(X_test_scaled, training=True)\n",
    "                     for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)\n",
    "y_std = y_probas.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model.predict(X_test_scaled[:1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.46, 0.  , 0.5 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.28, 0.  , 0.72]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.18, 0.  , 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.52, 0.  , 0.47]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.03, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.56, 0.  , 0.44]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.07, 0.  , 0.78]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.01, 0.  , 0.88]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.32, 0.  , 0.68]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.06, 0.  , 0.92]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.02, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.17, 0.  , 0.13, 0.  , 0.7 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.3 , 0.  , 0.02, 0.  , 0.68]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.01, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.05, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.4 , 0.  , 0.59]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.04, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.04, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.08, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.03, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.39, 0.  , 0.6 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.02, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.07, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.01, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.4 , 0.  , 0.5 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.01, 0.  , 0.92]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.01, 0.  , 0.86]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.  , 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.26, 0.  , 0.08, 0.  , 0.66]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.29, 0.  , 0.55]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.24, 0.  , 0.17, 0.  , 0.59]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.27, 0.  , 0.72]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.23, 0.  , 0.07, 0.  , 0.7 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.  , 0.  , 0.92]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.01, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.04, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.37, 0.  , 0.53]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.22, 0.  , 0.08, 0.  , 0.7 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.58, 0.  , 0.39]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.74, 0.  , 0.01, 0.  , 0.25]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.17, 0.  , 0.01, 0.  , 0.83]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.21, 0.  , 0.73]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.16, 0.  , 0.79]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.1 , 0.  , 0.79]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.03, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.21, 0.  , 0.73]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.47, 0.  , 0.53]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.18, 0.  , 0.02, 0.  , 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.35, 0.  , 0.65]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.01, 0.12, 0.  , 0.75]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.05, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.42, 0.  , 0.08, 0.  , 0.51]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.  , 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.  , 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.6 , 0.  , 0.4 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.22, 0.  , 0.72]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.12, 0.  , 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.01, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.4 , 0.  , 0.  , 0.  , 0.6 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.42, 0.  , 0.56]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.49, 0.  , 0.12, 0.  , 0.4 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.95, 0.  , 0.02, 0.  , 0.03]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.09, 0.  , 0.88]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.76, 0.  , 0.07, 0.  , 0.17]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.46, 0.  , 0.42, 0.  , 0.12]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.36, 0.  , 0.03, 0.  , 0.61]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.01, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.22, 0.  , 0.77]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.03, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.52, 0.  , 0.01, 0.  , 0.47]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.78, 0.  , 0.05, 0.  , 0.16]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_probas[:, :1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.11, 0.  , 0.78]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_proba[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8669"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "Alternatively if we have layers that are not dropout, e.g., BN, we should not force training=True for them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)\n",
    "\n",
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method MCAlphaDropout.call of <__main__.MCAlphaDropout object at 0x00000247BD9860C8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <bound method MCAlphaDropout.call of <__main__.MCAlphaDropout object at 0x00000247BD9860C8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method MCAlphaDropout.call of <__main__.MCAlphaDropout object at 0x00000247BD9861C8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <bound method MCAlphaDropout.call of <__main__.MCAlphaDropout object at 0x00000247BD9861C8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method MCAlphaDropout.call of <__main__.MCAlphaDropout object at 0x00000247BD986208>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <bound method MCAlphaDropout.call of <__main__.MCAlphaDropout object at 0x00000247BD986208>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "mc_model = keras.models.Sequential([\n",
    "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
    "    for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_17 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout (MCAlphaDro (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_1 (MCAlphaD (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_2 (MCAlphaD (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "mc_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.11, 0.  , 0.81]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.mean([mc_model.predict(X_test_scaled[:1]) for sample in range(100)], axis=0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.4743 - accuracy: 0.8349 - val_loss: 0.4021 - val_accuracy: 0.8594\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 4s 78us/sample - loss: 0.3579 - accuracy: 0.8683 - val_loss: 0.3456 - val_accuracy: 0.8756\n"
     ]
    }
   ],
   "source": [
    "MaxNormDense = partial(keras.layers.Dense,\n",
    "                       activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       kernel_constraint=keras.constraints.max_norm(1.))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    MaxNormDense(300),\n",
    "    MaxNormDense(100),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
